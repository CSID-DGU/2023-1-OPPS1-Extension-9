{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6tc4UHZR_DQE"
      },
      "source": [
        "**bert**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ES5T_QFKZRC",
        "outputId": "646c0f39-62bb-4276-fd5a-cf89ffb31fde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy==1.23.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rF62eXBIaYm",
        "outputId": "1a75aebe-a28b-4870-9671-f5ebec06dd76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: boto3==1.15.18 in /usr/local/lib/python3.10/dist-packages (1.15.18)\n",
            "Requirement already satisfied: botocore<1.19.0,>=1.18.18 in /usr/local/lib/python3.10/dist-packages (from boto3==1.15.18) (1.18.18)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3==1.15.18) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from boto3==1.15.18) (0.3.7)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.19.0,>=1.18.18->boto3==1.15.18) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.10/dist-packages (from botocore<1.19.0,>=1.18.18->boto3==1.15.18) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.19.0,>=1.18.18->boto3==1.15.18) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install boto3==1.15.18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hejrBHKcH9Ta",
        "outputId": "1e0e957b-e726-42d9-db01-6a66602a5ff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gluonnlp==0.8.0\n",
            "  Downloading gluonnlp-0.8.0.tar.gz (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gluonnlp==0.8.0) (1.23.5)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.8.0-py3-none-any.whl size=292701 sha256=c9c0d1a1960db1d3b2a8a440c3b791c44d8871a8084ad1d1cb0b34a2c7a3b003\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/cc/dc/7ec84dced25f738b8be400101abb67e4b50c905090a51017e4\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "  Attempting uninstall: gluonnlp\n",
            "    Found existing installation: gluonnlp 0.10.0\n",
            "    Uninstalling gluonnlp-0.10.0:\n",
            "      Successfully uninstalled gluonnlp-0.10.0\n",
            "Successfully installed gluonnlp-0.8.0\n"
          ]
        }
      ],
      "source": [
        "pip install gluonnlp==0.8.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6qNE1VylS-q"
      },
      "outputs": [],
      "source": [
        "pip install mxnet==1.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihzX5Ta_IPA_",
        "outputId": "037d17f1-8450-411d-d45b-55f3429b311e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4KOUS9lIJ4W",
        "outputId": "9b0a59ce-4a90-4cfd-aa4d-7d85f00ae3e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (1.15.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.3.3)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.11.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYEGp4YblmZ7"
      },
      "outputs": [],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4jBS6gylqDg"
      },
      "outputs": [],
      "source": [
        "pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jCBmEzL9_D4_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class BERT(nn.Module):\n",
        "    def __init__(self, bert):\n",
        "        super(BERT, self).__init__()\n",
        "        self.bert = bert\n",
        "\n",
        "    def forward(self, inputs, mode):\n",
        "\n",
        "        if mode == 'train':\n",
        "            anchor_attention_mask = self.gen_attention_mask(inputs['anchor']['source'],\n",
        "                                                            inputs['anchor']['valid_length'])\n",
        "\n",
        "            positive_attention_mask = self.gen_attention_mask(inputs['positive']['source'],\n",
        "                                                              inputs['positive']['valid_length'])\n",
        "\n",
        "            negative_attention_mask = self.gen_attention_mask(inputs['negative']['source'],\n",
        "                                                              inputs['negative']['valid_length'])\n",
        "\n",
        "            _, anchor_pooler = self.bert(input_ids=inputs['anchor']['source'],\n",
        "                                         token_type_ids=inputs['anchor']['segment_ids'],\n",
        "                                         attention_mask=anchor_attention_mask)\n",
        "\n",
        "            _, positive_pooler = self.bert(input_ids=inputs['positive']['source'],\n",
        "                                           token_type_ids=inputs['positive']['segment_ids'],\n",
        "                                           attention_mask=positive_attention_mask)\n",
        "\n",
        "            _, negative_pooler = self.bert(input_ids=inputs['negative']['source'],\n",
        "                                           token_type_ids=inputs['negative']['segment_ids'],\n",
        "                                           attention_mask=negative_attention_mask)\n",
        "\n",
        "            return anchor_pooler, positive_pooler, negative_pooler\n",
        "\n",
        "        else:\n",
        "            sentence_1_attention_mask = self.gen_attention_mask(inputs['sentence_1']['source'],\n",
        "                                                                inputs['sentence_1']['valid_length'])\n",
        "\n",
        "            sentence_2_attention_mask = self.gen_attention_mask(inputs['sentence_2']['source'],\n",
        "                                                                inputs['sentence_2']['valid_length'])\n",
        "\n",
        "            _, sentence_1_pooler = self.bert(input_ids=inputs['sentence_1']['source'],\n",
        "                                             token_type_ids=inputs['sentence_1']['segment_ids'],\n",
        "                                             attention_mask=sentence_1_attention_mask)\n",
        "\n",
        "            _, sentence_2_pooler = self.bert(input_ids=inputs['sentence_2']['source'],\n",
        "                                             token_type_ids=inputs['sentence_2']['segment_ids'],\n",
        "                                             attention_mask=sentence_2_attention_mask)\n",
        "\n",
        "            return sentence_1_pooler, sentence_2_pooler\n",
        "\n",
        "    def encode(self, inputs, device):\n",
        "\n",
        "        attention_mask = self.gen_attention_mask(inputs['source'], inputs['valid_length'])\n",
        "\n",
        "        _, embeddings = self.bert(input_ids=inputs['source'].to(device),\n",
        "                                  token_type_ids=inputs['segment_ids'].to(device),\n",
        "                                  attention_mask=attention_mask.to(device))\n",
        "\n",
        "        return embeddings\n",
        "\n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "\n",
        "        return attention_mask.float()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aG52gmcY_L-H"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hTTHeOcj-7DX"
      },
      "source": [
        "**utils**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUHsJ0CX_z5E",
        "outputId": "d0918636-62d1-48cf-a3ce-e28752d4947e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.10/dist-packages (2.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (23.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorboardx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ipL8Db9G-7qt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import logging\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "writer = SummaryWriter()\n",
        "\n",
        "\n",
        "class Metric():\n",
        "\n",
        "    def __init__(self, args):\n",
        "        self.args = args\n",
        "\n",
        "    def get_lr(self, optimizer):\n",
        "        return optimizer.state_dict()['param_groups'][0]['lr']\n",
        "\n",
        "    def count_parameters(self, model):\n",
        "        print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "    def cal_acc(self, yhat, y):\n",
        "        with torch.no_grad():\n",
        "            yhat = yhat.max(dim=-1)[1]  # [0]: max value, [1]: index of max value\n",
        "            acc = (yhat == y).float().mean()\n",
        "\n",
        "        return acc\n",
        "\n",
        "    def cal_time(self, start_time, end_time):\n",
        "        elapsed_time = end_time - start_time\n",
        "        elapsed_mins = int(elapsed_time / 60)\n",
        "        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "\n",
        "        return elapsed_mins, elapsed_secs\n",
        "\n",
        "    def cal_dev_score(self, score, indicator):\n",
        "        validation_score = score['score'] / score['iter']\n",
        "        for key, value in indicator.items():\n",
        "            indicator[key] /= score['iter']\n",
        "\n",
        "        print(\"\\n\\nCosine-Similarity :\\tPearson: {:.4f}\\tSpearman: {:.4f}\".format(\n",
        "            indicator['eval_pearson_cosine'], indicator['eval_spearman_cosine']))\n",
        "        print(\"Manhattan-Distance:\\tPearson: {:.4f}\\tSpearman: {:.4f}\".format(\n",
        "            indicator['eval_pearson_manhattan'], indicator['eval_spearman_manhattan']))\n",
        "        print(\"Euclidean-Distance:\\tPearson: {:.4f}\\tSpearman: {:.4f}\".format(\n",
        "            indicator['eval_pearson_euclidean'], indicator['eval_spearman_euclidean']))\n",
        "        print(\"Dot-Product-Similarity:\\tPearson: {:.4f}\\tSpearman: {:.4f}\\n\".format(\n",
        "            indicator['eval_pearson_dot'], indicator['eval_spearman_dot']))\n",
        "\n",
        "        return validation_score\n",
        "\n",
        "    def update_indicator(self, indicator, score):\n",
        "        for key, value in indicator.items():\n",
        "            if key == 'eval_spearman_cosine':\n",
        "                indicator[key] += score['eval_spearman_cosine']\n",
        "            elif key == 'eval_pearson_cosine':\n",
        "                indicator[key] += score['eval_pearson_cosine']\n",
        "            elif key == 'eval_spearman_manhattan':\n",
        "                indicator[key] += score['eval_spearman_manhattan']\n",
        "            elif key == 'eval_pearson_manhattan':\n",
        "                indicator[key] += score['eval_pearson_manhattan']\n",
        "            elif key == 'eval_spearman_euclidean':\n",
        "                indicator[key] += score['eval_spearman_euclidean']\n",
        "            elif key == 'eval_pearson_euclidean':\n",
        "                indicator[key] += score['eval_pearson_euclidean']\n",
        "            elif key == 'eval_spearman_dot':\n",
        "                indicator[key] += score['eval_spearman_dot']\n",
        "            elif key == 'eval_pearson_dot':\n",
        "                indicator[key] += score['eval_pearson_dot']\n",
        "\n",
        "    def draw_graph(self, cp):\n",
        "        writer.add_scalars('loss_graph', {'train': cp['tl'], 'valid': cp['vl']}, cp['ep'])\n",
        "        writer.add_scalars('acc_graph', {'train': cp['tma'], 'valid': cp['vma']}, cp['ep'])\n",
        "\n",
        "    def performance_check(self, cp, config):\n",
        "        print(f'\\t==Epoch: {cp[\"ep\"] + 1:02} | Epoch Time: {cp[\"epm\"]}m {cp[\"eps\"]}s==')\n",
        "        print(f'\\t==Train Loss: {cp[\"tl\"]:.4f} | Train acc: {cp[\"tma\"]:.4f}==')\n",
        "        print(f'\\t==Valid Loss: {cp[\"vl\"]:.4f} | Valid acc: {cp[\"vma\"]:.4f}==')\n",
        "        print(f'\\t==Epoch latest LR: {self.get_lr(config[\"optimizer\"]):.9f}==\\n')\n",
        "\n",
        "    def print_size_of_model(self, model):\n",
        "        torch.save(model.state_dict(), \"temp.p\")\n",
        "        print('Size (MB):', os.path.getsize(\"temp.p\") / 1e6)\n",
        "        os.remove('temp.p')\n",
        "\n",
        "    def move2device(self, sample, device):\n",
        "        if len(sample) == 0:\n",
        "            return {}\n",
        "\n",
        "        def _move_to_device(maybe_tensor, device):\n",
        "            if torch.is_tensor(maybe_tensor):\n",
        "                return maybe_tensor.to(device)\n",
        "            elif isinstance(maybe_tensor, dict):\n",
        "                return {\n",
        "                    key: _move_to_device(value, device)\n",
        "                    for key, value in maybe_tensor.items()\n",
        "                    }\n",
        "            elif isinstance(maybe_tensor, list):\n",
        "                return [_move_to_device(x, device) for x in maybe_tensor]\n",
        "            elif isinstance(maybe_tensor, tuple):\n",
        "                return [_move_to_device(x, device) for x in maybe_tensor]\n",
        "            else:\n",
        "                return maybe_tensor\n",
        "\n",
        "        return _move_to_device(sample, device)\n",
        "\n",
        "    def save_model(self, config, cp, pco):\n",
        "        if not os.path.exists(config['args'].path_to_save):\n",
        "            os.makedirs(config['args'].path_to_save)\n",
        "\n",
        "        sorted_path = config['args'].path_to_save + config['args'].ckpt\n",
        "        if cp['vs'] > pco['best_valid_score']:\n",
        "            # pco['early_stop_patient'] = 0\n",
        "            pco['best_valid_score'] = cp['vs']\n",
        "\n",
        "            state = {'model': config['model'].state_dict(),\n",
        "                     'optimizer': config['optimizer'].state_dict()}\n",
        "\n",
        "            torch.save(state, sorted_path)\n",
        "            print(f'\\t## SAVE {sorted_path} |'\n",
        "                  f' valid_score: {cp[\"vs\"]:.4f} |'\n",
        "                  f' epochs: {cp[\"ep\"]} |'\n",
        "                  f' steps: {cp[\"step\"]} ##\\n')\n",
        "\n",
        "        # self.draw_graph(cp)\n",
        "        # self.performance_check(cp, config)\n",
        "\n",
        "\n",
        "def pytorch_cos_sim(a, b):\n",
        "    \"\"\"\n",
        "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
        "    This function can be used as a faster replacement for 1-scipy.spatial.distance.cdist(a,b)\n",
        "    :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n",
        "    \"\"\"\n",
        "    if not isinstance(a, torch.Tensor):\n",
        "        a = torch.tensor(a)\n",
        "\n",
        "    if not isinstance(b, torch.Tensor):\n",
        "        b = torch.tensor(b)\n",
        "\n",
        "    if len(a.shape) == 1:\n",
        "        a = a.unsqueeze(0)\n",
        "\n",
        "    if len(b.shape) == 1:\n",
        "        b = b.unsqueeze(0)\n",
        "\n",
        "    a_norm = a / a.norm(dim=1)[:, None]\n",
        "    b_norm = b / b.norm(dim=1)[:, None]\n",
        "    return torch.mm(a_norm, b_norm.transpose(0, 1))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "U-Utb0jd-4qh"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1wOovh__-u1J"
      },
      "source": [
        "**loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IuSuSZW8-uG9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import logging\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "from sklearn.metrics.pairwise import paired_cosine_distances, paired_euclidean_distances, paired_manhattan_distances\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class Loss():\n",
        "\n",
        "    def __init__(self, args):\n",
        "        self.args = args\n",
        "        self.cos = nn.CosineSimilarity(dim=-1)\n",
        "        self.metric = Metric(args)\n",
        "\n",
        "    def train_loss_fct(self, config, a, p, n):\n",
        "\n",
        "        positive_similarity = self.cos(a.unsqueeze(1), p.unsqueeze(0)) / self.args.temperature\n",
        "        negative_similarity = self.cos(a.unsqueeze(1), n.unsqueeze(0)) / self.args.temperature\n",
        "        cosine_similarity = torch.cat([positive_similarity, negative_similarity], dim=1).to(self.args.device)\n",
        "\n",
        "        labels = torch.arange(cosine_similarity.size(0)).long().to(self.args.device)\n",
        "\n",
        "        loss = config['criterion'](cosine_similarity, labels)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def evaluation_during_training(self, embeddings1, embeddings2, labels, indicator):\n",
        "\n",
        "        embeddings1 = embeddings1.cpu().numpy()\n",
        "        embeddings2 = embeddings2.cpu().numpy()\n",
        "        labels = labels.cpu().numpy().flatten()\n",
        "\n",
        "        cosine_scores = 1 - (paired_cosine_distances(embeddings1, embeddings2))\n",
        "        manhattan_distances = -paired_manhattan_distances(embeddings1, embeddings2)\n",
        "        euclidean_distances = -paired_euclidean_distances(embeddings1, embeddings2)\n",
        "        dot_products = [np.dot(emb1, emb2) for emb1, emb2 in zip(embeddings1, embeddings2)]\n",
        "\n",
        "        eval_pearson_cosine, _ = pearsonr(labels, cosine_scores)\n",
        "        eval_spearman_cosine, _ = spearmanr(labels, cosine_scores)\n",
        "\n",
        "        eval_pearson_manhattan, _ = pearsonr(labels, manhattan_distances)\n",
        "        eval_spearman_manhattan, _ = spearmanr(labels, manhattan_distances)\n",
        "\n",
        "        eval_pearson_euclidean, _ = pearsonr(labels, euclidean_distances)\n",
        "        eval_spearman_euclidean, _ = spearmanr(labels, euclidean_distances)\n",
        "\n",
        "        eval_pearson_dot, _ = pearsonr(labels, dot_products)\n",
        "        eval_spearman_dot, _ = spearmanr(labels, dot_products)\n",
        "\n",
        "        score = {'eval_pearson_cosine': eval_pearson_cosine,\n",
        "                 'eval_spearman_cosine': eval_spearman_cosine,\n",
        "                 'eval_pearson_manhattan': eval_pearson_manhattan,\n",
        "                 'eval_spearman_manhattan': eval_spearman_manhattan,\n",
        "                 'eval_pearson_euclidean': eval_pearson_euclidean,\n",
        "                 'eval_spearman_euclidean': eval_spearman_euclidean,\n",
        "                 'eval_pearson_dot': eval_pearson_dot,\n",
        "                 'eval_spearman_dot': eval_spearman_dot}\n",
        "\n",
        "        self.metric.update_indicator(indicator, score)\n",
        "\n",
        "        return max(eval_spearman_cosine, eval_spearman_manhattan, eval_spearman_euclidean, eval_spearman_dot)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "u5JkT0dc-r-n"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HwJObmIFByp-"
      },
      "source": [
        "**aws_s3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7zyM81-B47h",
        "outputId": "cd8c4274-8fc7-407e-ba1c-aefb8ade0fbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".cache/kobert_news_wiki_ko_cased-1087f8699e.spiece[██████████████████████████████████████████████████]\n"
          ]
        }
      ],
      "source": [
        "import boto3\n",
        "import os\n",
        "import sys\n",
        "from botocore import UNSIGNED\n",
        "from botocore.client import Config\n",
        "\n",
        "\n",
        "class AwsS3Downloader(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        aws_access_key_id=None,\n",
        "        aws_secret_access_key=None,\n",
        "    ):\n",
        "        self.resource = boto3.Session(\n",
        "            aws_access_key_id=aws_access_key_id,\n",
        "            aws_secret_access_key=aws_secret_access_key,\n",
        "        ).resource(\"s3\")\n",
        "        self.client = boto3.client(\n",
        "            \"s3\",\n",
        "            aws_access_key_id=aws_access_key_id,\n",
        "            aws_secret_access_key=aws_secret_access_key,\n",
        "            config=Config(signature_version=UNSIGNED),\n",
        "        )\n",
        "\n",
        "    def __split_url(self, url: str):\n",
        "        if url.startswith(\"s3://\"):\n",
        "            url = url.replace(\"s3://\", \"\")\n",
        "        bucket, key = url.split(\"/\", maxsplit=1)\n",
        "        return bucket, key\n",
        "\n",
        "    def download(self, url: str, local_dir: str):\n",
        "        bucket, key = self.__split_url(url)\n",
        "        filename = os.path.basename(key)\n",
        "        file_path = os.path.join(local_dir, filename)\n",
        "\n",
        "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "        meta_data = self.client.head_object(Bucket=bucket, Key=key)\n",
        "        total_length = int(meta_data.get(\"ContentLength\", 0))\n",
        "\n",
        "        downloaded = 0\n",
        "\n",
        "        def progress(chunk):\n",
        "            nonlocal downloaded\n",
        "            downloaded += chunk\n",
        "            done = int(50 * downloaded / total_length)\n",
        "            sys.stdout.write(\n",
        "                \"\\r{}[{}{}]\".format(file_path, \"█\" * done, \".\" * (50 - done))\n",
        "            )\n",
        "            sys.stdout.flush()\n",
        "\n",
        "        try:\n",
        "            with open(file_path, \"wb\") as f:\n",
        "                self.client.download_fileobj(bucket, key, f, Callback=progress)\n",
        "            sys.stdout.write(\"\\n\")\n",
        "            sys.stdout.flush()\n",
        "        except:\n",
        "            raise Exception(f\"downloading file is failed. {url}\")\n",
        "        return file_path\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    s3 = AwsS3Downloader()\n",
        "\n",
        "    s3.download(\n",
        "        url=\"s3://skt-lsl-nlp-model/KoBERT/tokenizers/kobert_news_wiki_ko_cased-1087f8699e.spiece\",\n",
        "        local_dir=\".cache\",\n",
        "    )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "X4ulWVfzB5OB"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hiLW8gagCNXh"
      },
      "source": [
        "**kobert_utils**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ol4fTZY6COTx"
      },
      "outputs": [],
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2019 SK T-Brain Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "import hashlib\n",
        "import os\n",
        "\n",
        "\n",
        "def download(url, chksum=None, cachedir=\".cache\"):\n",
        "    cachedir_full = os.path.join(os.getcwd(), cachedir)\n",
        "    os.makedirs(cachedir_full, exist_ok=True)\n",
        "    filename = os.path.basename(url)\n",
        "    file_path = os.path.join(cachedir_full, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        if hashlib.md5(open(file_path, \"rb\").read()).hexdigest()[:10] == chksum[:10]:\n",
        "            print(f\"using cached model. {file_path}\")\n",
        "            return file_path, True\n",
        "\n",
        "    s3 = AwsS3Downloader()\n",
        "    file_path = s3.download(url, cachedir_full)\n",
        "    if chksum:\n",
        "        assert (\n",
        "            chksum[:10] == hashlib.md5(open(file_path, \"rb\").read()).hexdigest()[:10]\n",
        "        ), \"corrupted file!\"\n",
        "    return file_path, False\n",
        "\n",
        "\n",
        "def get_tokenizer(cachedir=\".cache\"):\n",
        "    \"\"\"Get KoBERT Tokenizer file path after downloading\"\"\"\n",
        "    tokenizer = {\n",
        "        \"url\": \"s3://skt-lsl-nlp-model/KoBERT/tokenizers/kobert_news_wiki_ko_cased-1087f8699e.spiece\",\n",
        "        \"chksum\": \"ae5711deb3\",\n",
        "    }\n",
        "\n",
        "    model_info = tokenizer\n",
        "    model_path, is_cached = download(model_info[\"url\"], model_info[\"chksum\"], cachedir=cachedir)\n",
        "    return model_path"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G1y1y2TmCNqh"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5GUqen2eCmmU"
      },
      "source": [
        "**kobert_pytorch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByLVxmL2Cmw_",
        "outputId": "246b1fa9-b5d7-4bf3-9a98-c4c030739445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using cached model. /content/.cache/kobert_v1.zip\n",
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
            "torch.Size([2, 768])\n",
            "Vocab(size=8002, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")\n",
            "tensor([[-0.2461,  0.2428,  0.2590,  ..., -0.4861, -0.0731,  0.0756],\n",
            "        [-0.2478,  0.2420,  0.2552,  ..., -0.4877, -0.0727,  0.0754],\n",
            "        [-0.2472,  0.2420,  0.2561,  ..., -0.4874, -0.0733,  0.0765]],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2019 SK T-Brain Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "import torch\n",
        "from transformers import BertModel\n",
        "import gluonnlp\n",
        "\n",
        "#from kobert import download, get_tokenizer\n",
        "\n",
        "\n",
        "def get_pytorch_kobert_model(ctx=\"cpu\", cachedir=\".cache\"):\n",
        "    def get_kobert_model(model_path, vocab_file, ctx=\"cpu\"):\n",
        "        bertmodel = BertModel.from_pretrained(model_path, return_dict=False)\n",
        "        device = torch.device(ctx)\n",
        "        bertmodel.to(device)\n",
        "        bertmodel.eval()\n",
        "        vocab_b_obj = gluonnlp.vocab.BERTVocab.from_sentencepiece(\n",
        "            vocab_file, padding_token=\"[PAD]\"\n",
        "        )\n",
        "        return bertmodel, vocab_b_obj\n",
        "\n",
        "    pytorch_kobert = {\n",
        "        \"url\": \"s3://skt-lsl-nlp-model/KoBERT/models/kobert_v1.zip\",\n",
        "        \"chksum\": \"411b242919\",  # 411b2429199bc04558576acdcac6d498\n",
        "    }\n",
        "\n",
        "    # download model\n",
        "    model_info = pytorch_kobert\n",
        "    model_path, is_cached = download(\n",
        "        model_info[\"url\"], model_info[\"chksum\"], cachedir=cachedir\n",
        "    )\n",
        "    cachedir_full = os.path.expanduser(cachedir)\n",
        "    zipf = ZipFile(os.path.expanduser(model_path))\n",
        "    zipf.extractall(path=cachedir_full)\n",
        "    model_path = os.path.join(os.path.expanduser(cachedir), \"kobert_from_pretrained\")\n",
        "    # download vocab\n",
        "    vocab_path = get_tokenizer()\n",
        "    return get_kobert_model(model_path, vocab_path, ctx)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import torch\n",
        "    #from kobert import get_pytorch_kobert_model\n",
        "\n",
        "    input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
        "    input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
        "    token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n",
        "    model, vocab = get_pytorch_kobert_model()\n",
        "    sequence_output, pooled_output = model(input_ids, input_mask, token_type_ids)\n",
        "    print(pooled_output.shape)\n",
        "    print(vocab)\n",
        "    print(sequence_output[0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W_kjLVHuCm8a"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6Eo-P9qW-O22"
      },
      "source": [
        "**setting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "R6mZo9jw-OH-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import logging\n",
        "import numpy as np\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "\n",
        "class Arguments():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.parser = ArgumentParser()\n",
        "\n",
        "    def add_type_of_processing(self):\n",
        "        self.add_argument('--opt_level', type=str, default='O1')\n",
        "        self.add_argument('--fp16', type=str, default='True')\n",
        "        self.add_argument('--train', type=str, default='True')\n",
        "        self.add_argument('--test', type=str, default='True')\n",
        "        self.add_argument('--device', type=str, default=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
        "\n",
        "    def add_hyper_parameters(self):\n",
        "        self.add_argument('--patient', type=int, default=10)\n",
        "        self.add_argument('--dropout', type=int, default=0.1)\n",
        "        self.add_argument('--max_len', type=int, default=50)\n",
        "        self.add_argument('--batch_size', type=int, default=256)\n",
        "        self.add_argument('--epochs', type=int, default=3)\n",
        "        self.add_argument('--eval_steps', type=int, default=250)\n",
        "        self.add_argument('--seed', type=int, default=1234)\n",
        "        self.add_argument('--lr', type=float, default=0.00005)\n",
        "        self.add_argument('--weight_decay', type=float, default=0.0)\n",
        "        self.add_argument('--warmup_ratio', type=float, default=0.05)\n",
        "        self.add_argument('--temperature', type=float, default=0.05)\n",
        "\n",
        "    def add_data_parameters(self):\n",
        "        self.add_argument('--train_data', type=str, default='snli_train.tsv')\n",
        "        self.add_argument('--valid_data', type=str, default='sts-dev.tsv')\n",
        "        self.add_argument('--test_data', type=str, default='sts_test.tsv')\n",
        "        self.add_argument('--task', type=str, default='NLU')\n",
        "        self.add_argument('--path_to_data', type=str, default='./data/')\n",
        "        #self.add_argument('--path_to_save', type=str, default='./output/')\n",
        "        self.add_argument('--path_to_save', type=str, default='/')\n",
        "        #self.add_argument('--path_to_saved_model', type=str, default='./output/')\n",
        "        self.add_argument('--path_to_saved_model', type=str, default='/')\n",
        "        self.add_argument('--ckpt', type=str, default='best_checkpoint.pt')\n",
        "\n",
        "    def print_args(self, args):\n",
        "        for idx, (key, value) in enumerate(args.__dict__.items()):\n",
        "            if idx == 0:print(\"argparse{\\n\", \"\\t\", key, \":\", value)\n",
        "            elif idx == len(args.__dict__) - 1:print(\"\\t\", key, \":\", value, \"\\n}\")\n",
        "            else:print(\"\\t\", key, \":\", value)\n",
        "\n",
        "    def add_argument(self, *args, **kw_args):\n",
        "        return self.parser.add_argument(*args, **kw_args)\n",
        "\n",
        "    def parse(self):\n",
        "        print(\"여기까지는 실행됨\")\n",
        "        args = self.parser.parse_args(\"\")\n",
        "        print(\"여기까지는 실행됨22222\")\n",
        "        self.print_args(args)\n",
        "        print(\"여기까지는 실행됨33333\")\n",
        "\n",
        "        return args\n",
        "\n",
        "\n",
        "class Setting():\n",
        "\n",
        "    def set_logger(self):\n",
        "\n",
        "        _logger = logging.getLogger()\n",
        "        formatter = logging.Formatter(\n",
        "            '[%(levelname)s] %(asctime)s [ %(message)s ] | file::%(filename)s | line::%(lineno)s')\n",
        "\n",
        "        stream_handler = logging.StreamHandler()\n",
        "        stream_handler.setFormatter(formatter)\n",
        "\n",
        "        _logger.addHandler(stream_handler)\n",
        "        _logger.setLevel(logging.DEBUG)\n",
        "\n",
        "        return _logger\n",
        "\n",
        "    def set_seed(self, args):\n",
        "\n",
        "        seed = args.seed\n",
        "\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        torch.manual_seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    def run(self):\n",
        "\n",
        "        parser = Arguments()\n",
        "        parser.add_type_of_processing()\n",
        "        parser.add_hyper_parameters()\n",
        "        parser.add_data_parameters()\n",
        "\n",
        "        args = parser.parse()\n",
        "        logger = self.set_logger()\n",
        "        self.set_seed(args)\n",
        "\n",
        "        return args, logger"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IkOQ43pS-Prt"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "11OhgsqXAaFS"
      },
      "source": [
        "**dataloder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkQdddHaAdLn",
        "outputId": "ef49eb88-2dca-4426-feb2-bd911e209af1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "여기까지는 실행됨\n",
            "여기까지는 실행됨22222\n",
            "argparse{\n",
            " \t opt_level : O1\n",
            "\t fp16 : True\n",
            "\t train : True\n",
            "\t test : True\n",
            "\t device : cpu\n",
            "\t patient : 10\n",
            "\t dropout : 0.1\n",
            "\t max_len : 50\n",
            "\t batch_size : 256\n",
            "\t epochs : 3\n",
            "\t eval_steps : 250\n",
            "\t seed : 1234\n",
            "\t lr : 5e-05\n",
            "\t weight_decay : 0.0\n",
            "\t warmup_ratio : 0.05\n",
            "\t temperature : 0.05\n",
            "\t train_data : snli_train_ko.tsv\n",
            "\t valid_data : sts-dev.tsv\n",
            "\t test_data : sts_test.tsv\n",
            "\t task : NLU\n",
            "\t path_to_data : ./data/\n",
            "\t path_to_save : /\n",
            "\t path_to_saved_model : /\n",
            "\t ckpt : best_checkpoint.pt \n",
            "}\n",
            "여기까지는 실행됨33333\n",
            "using cached model. /content/.cache/kobert_v1.zip\n",
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy\n",
        "import torch\n",
        "import logging\n",
        "import gluonnlp as nlp\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "#from KoBERT.kobert.utils import get_tokenizer\n",
        "#from KoBERT.kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class ModelDataLoader(Dataset):\n",
        "    def __init__(self, file_path, args, metric, tokenizer, vocab, type):\n",
        "        self.type = type\n",
        "        self.args = args\n",
        "        self.vocab = vocab\n",
        "        self.metric = metric\n",
        "\n",
        "        \"\"\"NLI\"\"\"\n",
        "        self.anchor = []\n",
        "        self.positive = []\n",
        "        self.negative = []\n",
        "\n",
        "        \"\"\"STS\"\"\"\n",
        "        self.label = []\n",
        "        self.sentence_1 = []\n",
        "        self.sentence_2 = []\n",
        "\n",
        "        #  -------------------------------------\n",
        "        self.bert_tokenizer = tokenizer\n",
        "\n",
        "        self.transform = nlp.data.BERTSentenceTransform(\n",
        "            self.bert_tokenizer, max_seq_length=self.args.max_len, pad=True, pair=False)\n",
        "\n",
        "        self.file_path = file_path\n",
        "\n",
        "        \"\"\"\n",
        "        [CLS]: 2\n",
        "        [PAD]: 1\n",
        "        [UNK]: 0\n",
        "        \"\"\"\n",
        "        self.init_token = self.vocab.cls_token\n",
        "        self.pad_token = self.vocab.padding_token\n",
        "        self.unk_token = self.vocab.unknown_token\n",
        "\n",
        "        self.init_token_idx = self.vocab.token_to_idx[self.init_token]\n",
        "        self.pad_token_idx = self.vocab.token_to_idx[self.pad_token]\n",
        "        self.unk_token_idx = self.vocab.token_to_idx[self.unk_token]\n",
        "\n",
        "    def load_data(self, type):\n",
        "\n",
        "        with open(self.file_path) as file:\n",
        "            lines = file.readlines()\n",
        "\n",
        "            for line in lines:\n",
        "                self.data2tensor(line, type)\n",
        "\n",
        "        if type == 'train':\n",
        "            assert len(self.anchor) == len(self.positive) == len(self.negative)\n",
        "        else:\n",
        "            assert len(self.sentence_1) == len(self.sentence_2) == len(self.label)\n",
        "\n",
        "    def data2tensor(self, line, type):\n",
        "        split_data = line.split('\\t')\n",
        "\n",
        "        if type == 'train':\n",
        "            anchor, positive, negative = split_data\n",
        "            anchor = self.transform([anchor])\n",
        "            positive = self.transform([positive])\n",
        "            negative = self.transform([negative])\n",
        "\n",
        "            self.anchor.append(anchor)\n",
        "            self.positive.append(positive)\n",
        "            self.negative.append(negative)\n",
        "\n",
        "        else:\n",
        "            sentence_1, sentence_2, label = split_data\n",
        "            sentence_1 = self.transform([sentence_1])\n",
        "            sentence_2 = self.transform([sentence_2])\n",
        "\n",
        "            self.sentence_1.append(sentence_1)\n",
        "            self.sentence_2.append(sentence_2)\n",
        "            self.label.append(float(label.strip())/5.0)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        if self.type == 'train':\n",
        "            inputs = {'anchor': {\n",
        "                'source': torch.LongTensor(self.anchor[index][0]),\n",
        "                'valid_length': torch.tensor(self.anchor[index][1]),\n",
        "                'segment_ids': torch.LongTensor(self.anchor[index][2])\n",
        "                },\n",
        "                      'positive': {\n",
        "                'source': torch.LongTensor(self.positive[index][0]),\n",
        "                'valid_length': torch.tensor(self.positive[index][1]),\n",
        "                'segment_ids': torch.LongTensor(self.positive[index][2])\n",
        "                },\n",
        "                      'negative': {\n",
        "                'source': torch.LongTensor(self.negative[index][0]),\n",
        "                'valid_length': torch.tensor(self.negative[index][1]),\n",
        "                'segment_ids': torch.LongTensor(self.negative[index][2])\n",
        "                }}\n",
        "        else:\n",
        "\n",
        "            inputs = {'sentence_1': {\n",
        "                'source': torch.LongTensor(self.sentence_1[index][0]),\n",
        "                'valid_length': torch.tensor(self.sentence_1[index][1]),\n",
        "                'segment_ids': torch.LongTensor(self.sentence_1[index][2])\n",
        "                },\n",
        "                      'sentence_2': {\n",
        "                'source': torch.LongTensor(self.sentence_2[index][0]),\n",
        "                'valid_length': torch.tensor(self.sentence_2[index][1]),\n",
        "                'segment_ids': torch.LongTensor(self.sentence_2[index][2])\n",
        "                },\n",
        "                      'label': torch.FloatTensor([self.label[index]])}\n",
        "\n",
        "        inputs = self.metric.move2device(inputs, self.args.device)\n",
        "\n",
        "        return inputs\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.type == 'train':\n",
        "            return len(self.anchor)\n",
        "        else:\n",
        "            return len(self.label)\n",
        "\n",
        "\n",
        "# Get train, valid, test data loader and BERT tokenizer\n",
        "def get_loader(args, metric = 'accuracy'):\n",
        "    bert_model, vocab = get_pytorch_kobert_model()\n",
        "    tokenizer = get_tokenizer()\n",
        "    tokenizer = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "\n",
        "    path_to_train_data = args.train_data\n",
        "    # args.path_to_data + '/' + args.task + '/' + args.train_data\n",
        "    path_to_valid_data = args.valid_data\n",
        "    # args.path_to_data + '/' + args.task + '/' + args.valid_data\n",
        "    path_to_test_data = args.test_data\n",
        "    # args.path_to_data + '/' + args.task + '/' + args.test_data\n",
        "\n",
        "    if args.train == 'True' and args.test == 'False':\n",
        "        train_iter = ModelDataLoader(path_to_train_data, args, metric, tokenizer, vocab, type='train')\n",
        "        valid_iter = ModelDataLoader(path_to_valid_data, args, metric, tokenizer, vocab, type='valid')\n",
        "\n",
        "        train_iter.load_data('train')\n",
        "        valid_iter.load_data('valid')\n",
        "\n",
        "        loader = {'train': DataLoader(dataset=train_iter,\n",
        "                                      batch_size=args.batch_size,\n",
        "                                      shuffle=True),\n",
        "                  'valid': DataLoader(dataset=valid_iter,\n",
        "                                      batch_size=args.batch_size,\n",
        "                                      shuffle=True)}\n",
        "\n",
        "    elif args.train == 'False' and args.test == 'True':\n",
        "        test_iter = ModelDataLoader(path_to_test_data, args, metric, tokenizer, vocab, type='test')\n",
        "        test_iter.load_data('test')\n",
        "\n",
        "        loader = {'test': DataLoader(dataset=test_iter,\n",
        "                                     batch_size=args.batch_size,\n",
        "                                     shuffle=True)}\n",
        "\n",
        "    else:\n",
        "        loader = None\n",
        "\n",
        "    return bert_model, loader, tokenizer\n",
        "\n",
        "\n",
        "def convert_to_tensor(corpus, transform):\n",
        "    tensor_corpus = []\n",
        "    tensor_valid_length = []\n",
        "    tensor_segment_ids = []\n",
        "    for step, sentence in enumerate(corpus):\n",
        "        cur_sentence, valid_length, segment_ids = transform([sentence])\n",
        "\n",
        "        tensor_corpus.append(cur_sentence)\n",
        "        tensor_valid_length.append(numpy.array([valid_length]))\n",
        "        tensor_segment_ids.append(segment_ids)\n",
        "\n",
        "    inputs = {'source': torch.LongTensor(tensor_corpus),\n",
        "              'segment_ids': torch.LongTensor(tensor_segment_ids),\n",
        "              'valid_length': torch.tensor(tensor_valid_length)}\n",
        "\n",
        "    return inputs\n",
        "\n",
        "\n",
        "def example_model_setting(model_ckpt):\n",
        "\n",
        "    from model.simcse.bert import BERT\n",
        "\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    bert_model, vocab = get_pytorch_kobert_model()\n",
        "    tokenizer = nlp.data.BERTSPTokenizer(get_tokenizer(), vocab, lower=False)\n",
        "    transform = nlp.data.BERTSentenceTransform(tokenizer, max_seq_length=50, pad=True, pair=False)\n",
        "\n",
        "    model = BERT(bert_model)\n",
        "\n",
        "    model.load_state_dict(torch.load(model_ckpt)['model'])\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    return model, transform, device\n",
        "\n",
        "gs = Setting()\n",
        "args, logger = gs.run()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    get_loader(args, logger)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fMq6pSIZAYIB"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Om2uDsQa_PrV"
      },
      "source": [
        "**Processor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WAnt2C9h7K-",
        "outputId": "5a6ef728-623b-4d57-9db2-9b7acfd3bf98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cxxfilt\n",
            "  Downloading cxxfilt-0.3.0-py2.py3-none-any.whl (4.6 kB)\n",
            "Installing collected packages: cxxfilt\n",
            "Successfully installed cxxfilt-0.3.0\n"
          ]
        }
      ],
      "source": [
        "pip install cxxfilt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkBTv15biAu1",
        "outputId": "95f182f8-47e4-4878-92d2-84ca93260143"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnUagMYyiFmT",
        "outputId": "f3a89ffa-b535-4224-c83c-4f4b0457b41b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (6.0)\n"
          ]
        }
      ],
      "source": [
        "pip install PyYAML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2F_oWYDiRBB"
      },
      "outputs": [],
      "source": [
        "pip install pytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUBpMZfpiUkm"
      },
      "outputs": [],
      "source": [
        "pip install packaging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOtpJUvdin6a"
      },
      "outputs": [],
      "source": [
        "%cd apex\n",
        "!python3 setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOUxm7h1_O7M",
        "outputId": "3b9b8f44-d05b-408f-c1dc-dd79af1289cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
            "[DEBUG] 2023-06-02 19:18:39,900 [ Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client. ] | file::tpu_cluster_resolver.py | line::32\n",
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
            "[INFO] 2023-06-02 19:18:41,644 [ NumExpr defaulting to 2 threads. ] | file::utils.py | line::160\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import logging\n",
        "from apex import amp\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import torch.quantization\n",
        "import torch.optim as optim\n",
        "#from data.dataloader import get_loader\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class Processor():\n",
        "\n",
        "    def __init__(self, args):\n",
        "        self.args = args\n",
        "        self.config = None\n",
        "        self.metric = Metric(args)\n",
        "        self.loss = Loss(args)\n",
        "        self.total_steps = 0\n",
        "        self.model_checker = {'early_stop': False,\n",
        "                              'early_stop_patient': 0,\n",
        "                              'best_valid_score': 0}\n",
        "        self.dev_progress = {'score': 0, 'iter': 0}\n",
        "        self.model_progress = {'loss': 0, 'iter': 0}\n",
        "\n",
        "    def run(self, inputs, indicator=None, type=None):\n",
        "\n",
        "        if type == 'train':\n",
        "            anchor_embeddings, positive_embeddings, negative_embeddings = self.config['model'](inputs, type)\n",
        "            loss = self.loss.train_loss_fct(self.config, anchor_embeddings, positive_embeddings, negative_embeddings)\n",
        "            return loss\n",
        "        else:\n",
        "            sentence_1_embeddings, sentence_2_embeddings = self.config['model'](inputs, type)\n",
        "            score = self.loss.evaluation_during_training(sentence_1_embeddings, sentence_2_embeddings, inputs['label'], indicator)\n",
        "            return score\n",
        "\n",
        "    def progress(self, loss):\n",
        "        self.model_progress['loss'] += loss\n",
        "        self.model_progress['iter'] += 1\n",
        "\n",
        "    def progress_validation(self, score):\n",
        "        self.dev_progress['score'] += score\n",
        "        self.dev_progress['iter'] += 1\n",
        "\n",
        "    def return_value(self):\n",
        "        loss = self.model_progress['loss'].data.cpu().numpy() / self.model_progress['iter']\n",
        "        acc = self.model_progress['acc'].data.cpu().numpy() / self.model_progress['iter']\n",
        "\n",
        "        return loss, acc\n",
        "\n",
        "    def get_object(self, tokenizer, model):\n",
        "\n",
        "        no_decay = ['bias', 'LayerNorm.weight']\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "             'weight_decay': self.args.weight_decay},\n",
        "            {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "             'weight_decay': 0.0}\n",
        "        ]\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.AdamW(optimizer_grouped_parameters, lr=self.args.lr)\n",
        "\n",
        "        return criterion, optimizer\n",
        "\n",
        "    def get_scheduler(self, optim, train_loader):\n",
        "        train_total = len(train_loader) * self.args.epochs\n",
        "        scheduler = get_linear_schedule_with_warmup(optim,\n",
        "                                                    num_warmup_steps=self.args.warmup_ratio * train_total,\n",
        "                                                    num_training_steps=train_total)\n",
        "\n",
        "        return scheduler, train_total\n",
        "\n",
        "    def model_setting(self):\n",
        "        model, loader, tokenizer = get_loader(self.args, self.metric)\n",
        "        model = BERT(model)\n",
        "        model.to(self.args.device)\n",
        "\n",
        "        criterion, optimizer = self.get_object(tokenizer, model)\n",
        "\n",
        "        if self.args.train == 'True':\n",
        "            scheduler, total_steps = self.get_scheduler(optimizer, loader['train'])\n",
        "            self.total_steps = total_steps\n",
        "        else:\n",
        "            scheduler = None\n",
        "\n",
        "        config = {'loader': loader,\n",
        "                  'optimizer': optimizer,\n",
        "                  'criterion': criterion,\n",
        "                  'scheduler': scheduler,\n",
        "                  'tokenizer': tokenizer,\n",
        "                  'args': self.args,\n",
        "                  'model': model}\n",
        "\n",
        "        if config['args'].fp16 == 'True':\n",
        "            config['model'], config['optimizer'] = amp.initialize(\n",
        "                config['model'], config['optimizer'], opt_level=config['args'].opt_level)\n",
        "\n",
        "        self.config = config\n",
        "\n",
        "        return self.config\n",
        "\n",
        "    def train(self, epoch):\n",
        "        self.config['model'].train()\n",
        "\n",
        "        for step, batch in enumerate(tqdm(self.config['loader']['train'])):\n",
        "            self.config['optimizer'].zero_grad()\n",
        "\n",
        "            inputs = batch\n",
        "\n",
        "            train_loss = self.run(inputs, type='train')\n",
        "\n",
        "            if self.args.fp16 == 'True':\n",
        "                with amp.scale_loss(train_loss, self.config['optimizer']) as scaled_loss:\n",
        "                    scaled_loss.backward()\n",
        "            else:\n",
        "                train_loss.backward()\n",
        "\n",
        "            self.config['optimizer'].step()\n",
        "            self.config['scheduler'].step()\n",
        "\n",
        "            self.progress(train_loss.data)\n",
        "\n",
        "            if self.model_progress['iter'] % self.args.eval_steps == 0 or self.model_progress['iter'] == self.total_steps:\n",
        "                valid_score = self.valid()\n",
        "                performance = {'tl': train_loss, 'vs': valid_score, 'ep': epoch, 'step': self.model_progress['iter']}\n",
        "                \n",
        "                self.metric.save_model(self.config, performance, self.model_checker)\n",
        "                self.config['model'].train()\n",
        "                \n",
        "    def valid(self):\n",
        "        self.config['model'].eval()\n",
        "        self.dev_progress = self.dev_progress.fromkeys(self.dev_progress, 0)\n",
        "\n",
        "        score_indicator = {'eval_pearson_cosine': 0,\n",
        "                           'eval_spearman_cosine': 0,\n",
        "                           'eval_pearson_manhattan': 0,\n",
        "                           'eval_spearman_manhattan': 0,\n",
        "                           'eval_pearson_euclidean': 0,\n",
        "                           'eval_spearman_euclidean': 0,\n",
        "                           'eval_pearson_dot': 0,\n",
        "                           'eval_spearman_dot': 0}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for step, batch in enumerate(self.config['loader']['valid']):\n",
        "                inputs = batch\n",
        "                score = self.run(inputs, indicator=score_indicator, type='valid')\n",
        "\n",
        "                self.progress_validation(score)\n",
        "\n",
        "        score = self.metric.cal_dev_score(self.dev_progress, score_indicator)\n",
        "\n",
        "        return score\n",
        "\n",
        "    def test(self):\n",
        "        self.config['model'].load_state_dict(torch.load(self.args.path_to_saved_model)['model'], strict=False)\n",
        "        self.config['model'].eval()\n",
        "        self.dev_progress = self.dev_progress.fromkeys(self.dev_progress, 0)\n",
        "\n",
        "        score_indicator = {'eval_pearson_cosine': 0,\n",
        "                           'eval_spearman_cosine': 0,\n",
        "                           'eval_pearson_manhattan': 0,\n",
        "                           'eval_spearman_manhattan': 0,\n",
        "                           'eval_pearson_euclidean': 0,\n",
        "                           'eval_spearman_euclidean': 0,\n",
        "                           'eval_pearson_dot': 0,\n",
        "                           'eval_spearman_dot': 0}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for step, batch in enumerate(self.config['loader']['test']):\n",
        "                inputs = batch\n",
        "                score = self.run(inputs, indicator=score_indicator, type='test')\n",
        "\n",
        "                self.progress_validation(score)\n",
        "\n",
        "        logger.info('### TEST SCORE ###')\n",
        "        score = self.metric.cal_dev_score(self.dev_progress, score_indicator)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1Gg16QN_BFT"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6hdcWuM7-IkE"
      },
      "source": [
        "**main**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAPifM4E-Cqo"
      },
      "outputs": [],
      "source": [
        "#from model.setting import Setting, Arguments\n",
        "#from model.simcse.processor import Processor\n",
        "\n",
        "\n",
        "def main(args, logger) -> None:\n",
        "    processor = Processor(args)\n",
        "    config = processor.model_setting()\n",
        "    logger.info('Model Setting Complete')\n",
        "\n",
        "    if args.train == 'True':\n",
        "        logger.info('Start Training')\n",
        "        \n",
        "        for epoch in range(args.epochs):\n",
        "            processor.train(epoch+1)\n",
        "\n",
        "    if args.test == 'True':\n",
        "        logger.info(\"Start Test\")\n",
        "        \n",
        "        processor.test()\n",
        "        processor.metric.print_size_of_model(config['model'])\n",
        "        processor.metric.count_parameters(config['model'])\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    args, logger = Setting().run()\n",
        "    main(args, logger)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
